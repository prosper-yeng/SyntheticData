# -*- coding: utf-8 -*-
"""Prosper_Classification_Scaled.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e3FR2c54D9Dbccl67VqyIgc2StSDQTBW
"""

# Commented out IPython magic to ensure Python compatibility.
from sklearn.preprocessing import StandardScaler
from sklearn import preprocessing
# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
import pandas as pd
import csv
from google.colab import drive


from sklearn.naive_bayes import BernoulliNB, MultinomialNB
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import precision_recall_fscore_support, precision_score, recall_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score, cross_validate, cross_val_predict

from google.colab import drive
drive.mount('/content/gdrive')
path_folder ="/content/gdrive/My Drive/PhD/Prosper/"

df = pd.read_excel(path_folder+'features_data_with_label.xlsx')
print(df)
df = df.loc[df['anomaly'] == 0]
print(df)

X = df[['number_of_create' , 'number_of_read' , 'number_of_update' , 'number_of_delete' , 'number_of_patient_record' , 'number_of_unique_patient_record' , 'number_of_modules' , 'number_of_report_module' , 'number_of_finance_module' , 'number_of_patient_module' , 'number_of_lab_module' , 'number_of_pharmacy_module' , 'number_of_access_warning' , 'number_of_outside_access' , 'number_of_browser' , 'number_of_chrome' , 'number_of_ie' , 'number_of_safari' , 'number_of_firefox' , 'number_of_otherbrowser' , 'anomaly']]
y = df['employee_role']

scaler = StandardScaler()

scaler.fit(X)

param_grid = [
  {'C': [1, 10, 100, 1000]}
 ]

bern_nb = Pipeline([('scale', StandardScaler()), ("bernoulli nb", BernoulliNB())])
mult_nb = Pipeline([('scale', StandardScaler()), ("multinomial nb", MultinomialNB())])
svm = Pipeline([('scale', StandardScaler()), ("linear svc", SVC(kernel='linear', probability=True))])
nn = Pipeline([('scale', StandardScaler()), ("neural network", MLPClassifier())])
knn = Pipeline([('scale', StandardScaler()), ("multinomial nb",  KNeighborsClassifier(5))])
lr = Pipeline([('scale', StandardScaler()), ("multinomial nb",  LogisticRegression())])
rf = Pipeline([('scale', StandardScaler()), ("multinomial nb", RandomForestClassifier())])
dt = Pipeline([('scale', StandardScaler()), ("multinomial nb", DecisionTreeClassifier())])

all_models = [
    ("mult_nb", mult_nb),
    ("bern_nb", bern_nb),
    ("nn", nn),
    ("knn", knn),
    ("lr", lr),
    ("rf", rf),
    ("dt", dt),
    ("svm", svm)
]

for name, model in all_models: 
  clf=model
  print(name)
  scoring = ['precision_macro', 'recall_macro', 'f1_macro']
  scores = cross_validate(clf, X, y, cv=5)
  print(scores)
  print(sum(scores['test_score'])/len(scores['test_score']))

# Commented out IPython magic to ensure Python compatibility.
from sklearn.preprocessing import StandardScaler
from sklearn import preprocessing

# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
import pandas as pd
import csv
from google.colab import drive


from sklearn.naive_bayes import BernoulliNB, MultinomialNB
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import precision_recall_fscore_support, precision_score, recall_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score, cross_validate, cross_val_predict

from google.colab import drive
drive.mount('/content/gdrive')
path_folder ="/content/gdrive/My Drive/PhD/Prosper/"

df = pd.read_excel(path_folder+'features_data_with_label_v2.xlsx')
print(df)
df = df.loc[df['anomaly'] == 0]
print(df)

X = df[['number_of_create' , 'number_of_read' , 'number_of_update' , 'number_of_delete' , 'number_of_patient_record' , 'number_of_unique_patient_record' , 'number_of_modules' , 'number_of_report_module' , 'number_of_finance_module' , 'number_of_patient_module' , 'number_of_lab_module' , 'number_of_pharmacy_module' , 'number_of_access_warning' , 'number_of_outside_access' , 'number_of_browser' , 'number_of_chrome' , 'number_of_ie' , 'number_of_safari' , 'number_of_firefox' , 'number_of_otherbrowser' , 'anomaly']]
y = df['employee_role']
param_grid = [
  {'C': [1, 10, 100, 1000]}
 ]


mult_nb = Pipeline([('scale', StandardScaler()), ("multinomial nb", MultinomialNB())])
bern_nb = Pipeline([('scale', StandardScaler()), ("bernoulli nb", BernoulliNB())])
svm = Pipeline([('scale', StandardScaler()), ("linear svc", SVC(kernel='linear', probability=True))])
nn = Pipeline([('scale', StandardScaler()), ("neural network", MLPClassifier())])
knn = Pipeline([('scale', StandardScaler()), ("multinomial nb",  KNeighborsClassifier(5))])
lr = Pipeline([('scale', StandardScaler()), ("multinomial nb",  LogisticRegression())])
rf = Pipeline([('scale', StandardScaler()), ("multinomial nb", RandomForestClassifier())])
dt = Pipeline([('scale', StandardScaler()), ("multinomial nb", DecisionTreeClassifier())])

all_models = [
    ("mult_nb", mult_nb),
    ("bern_nb", bern_nb),
    ("nn", nn),
    ("knn", knn),
    ("lr", lr),
    ("rf", rf),
    ("dt", dt),
    ("svm", svm)
]

for name, model in all_models: 
  clf=model
  #print(name)
  #result = cross_val_predict(clf, X, y, cv=5) # 5-fold Cross Validation
  #conf_mat = confusion_matrix(y, result)
  #print(conf_mat)
  #print("Precision Score : ",precision_score(y, result, average='micro'))
  #print("Recall Score : ",recall_score(y, result, average='micro'))
  #scoring = ['precision_macro', 'recall_macro', 'f1_macro']
  scores = cross_validate(clf, X, y, cv=5)
  #print(scores)
  print(name + '&' + str(sum(scores['test_score'])/len(scores['test_score']))+'\\\\')
  #print(sum(scores['test_score'])/len(scores['test_score']))
  #cross_val_score(clf, X, y, cv=5, scoring='precision_macro')

  #print(cross_val_score(clf, X, y, cv=5, scoring='recall_macro'))
  #print(cross_val_score(clf, X, y, cv=5, scoring='precision_micro'))
  #print(cross_val_score(clf, X, y, cv=5, scoring='recall_micro'))
  #print(cross_val_score(clf, X, y, cv=5, scoring='f1_macro'))
  #print(cross_val_score(clf, X, y, cv=5, scoring='f1_micro'))

# Commented out IPython magic to ensure Python compatibility.
from sklearn.preprocessing import StandardScaler
from sklearn import preprocessing
from sklearn.preprocessing import MinMaxScaler

# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
import pandas as pd
import csv
from google.colab import drive


from sklearn.naive_bayes import BernoulliNB, MultinomialNB
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import precision_recall_fscore_support, precision_score, recall_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score, cross_validate, cross_val_predict

from google.colab import drive
drive.mount('/content/gdrive')
path_folder ="/content/gdrive/My Drive/PhD/Prosper/"

df = pd.read_excel(path_folder+'features_data_with_label_v2.xlsx')
print(df)
df = df.loc[df['anomaly'] == 0]
print(df)

X = df[['number_of_create' , 'number_of_read' , 'number_of_update' , 'number_of_delete' , 'number_of_patient_record' , 'number_of_unique_patient_record' , 'number_of_modules' , 'number_of_report_module' , 'number_of_finance_module' , 'number_of_patient_module' , 'number_of_lab_module' , 'number_of_pharmacy_module' , 'number_of_access_warning' , 'number_of_outside_access' , 'number_of_browser' , 'number_of_chrome' , 'number_of_ie' , 'number_of_safari' , 'number_of_firefox' , 'number_of_otherbrowser' , 'anomaly']]
y = df['employee_role']
param_grid = [
  {'C': [1, 10, 100, 1000]}
 ]

bern_nb = Pipeline([('scale', MinMaxScaler()), ("bernoulli nb", BernoulliNB())])
mult_nb = Pipeline([('scale', MinMaxScaler()), ("multinomial nb", MultinomialNB())])
svm = Pipeline([('scale', MinMaxScaler()), ("linear svc", SVC(kernel='linear', probability=True))])
nn = Pipeline([('scale', MinMaxScaler()), ("neural network", MLPClassifier())])
knn = Pipeline([('scale', MinMaxScaler()), ("multinomial nb",  KNeighborsClassifier(5))])
lr = Pipeline([('scale', MinMaxScaler()), ("multinomial nb",  LogisticRegression())])
rf = Pipeline([('scale', MinMaxScaler()), ("multinomial nb", RandomForestClassifier())])
dt = Pipeline([('scale', MinMaxScaler()), ("multinomial nb", DecisionTreeClassifier())])

all_models = [
    ("mult_nb", mult_nb),
    ("bern_nb", bern_nb),
    ("nn", nn),
    ("knn", knn),
    ("lr", lr),
    ("rf", rf),
    ("dt", dt),
    ("svm", svm)
]

for name, model in all_models: 
  clf=model
  #print(name)
  #result = cross_val_predict(clf, X, y, cv=5) # 5-fold Cross Validation
  #conf_mat = confusion_matrix(y, result)
  #print(conf_mat)
  #print("Precision Score : ",precision_score(y, result, average='micro'))
  #print("Recall Score : ",recall_score(y, result, average='micro'))
  #scoring = ['precision_macro', 'recall_macro', 'f1_macro']
  scores = cross_validate(clf, X, y, cv=5)
  #print(scores)
  print(name + '&' + str(sum(scores['test_score'])/len(scores['test_score']))+'\\\\')
  #print(sum(scores['test_score'])/len(scores['test_score']))
  #cross_val_score(clf, X, y, cv=5, scoring='precision_macro')

  #print(cross_val_score(clf, X, y, cv=5, scoring='recall_macro'))
  #print(cross_val_score(clf, X, y, cv=5, scoring='precision_micro'))
  #print(cross_val_score(clf, X, y, cv=5, scoring='recall_micro'))
  #print(cross_val_score(clf, X, y, cv=5, scoring='f1_macro'))
  #print(cross_val_score(clf, X, y, cv=5, scoring='f1_micro'))

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
import pandas as pd
import csv
from google.colab import drive


from sklearn.naive_bayes import BernoulliNB, MultinomialNB
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import precision_recall_fscore_support, precision_score, recall_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score, cross_validate, cross_val_predict

from google.colab import drive
drive.mount('/content/gdrive')
path_folder ="/content/gdrive/My Drive/PhD/Prosper/"

df = pd.read_excel(path_folder+'features_data_with_label_v2.xlsx')
print(df['date'])
df['month']=df['date'].apply(lambda x: int(x.split('/')[1]))
print(df['month'])

df_first = df.loc[df['month'] <= 8]
print('training all: '+str(df_first.shape[0]))
df_training = df_first.loc[df_first['anomaly'] == 0]
print(df_training.shape[0])

df_testing = df.loc[df['month'] > 8]
print(df_testing.shape[0])

df_testing_anomaly = df.loc[df['anomaly'] == 1]
print(df_testing_anomaly.shape[0])

X = df_training[['number_of_create' , 'number_of_read' , 'number_of_update' , 'number_of_delete' , 'number_of_patient_record' , 'number_of_unique_patient_record' , 'number_of_modules' , 'number_of_report_module' , 'number_of_finance_module' , 'number_of_patient_module' , 'number_of_lab_module' , 'number_of_pharmacy_module' , 'number_of_access_warning' , 'number_of_outside_access' , 'number_of_browser' , 'number_of_chrome' , 'number_of_ie' , 'number_of_safari' , 'number_of_firefox' , 'number_of_otherbrowser' , 'anomaly']]
y = df_training['employee_role']

S = df_testing[['number_of_create' , 'number_of_read' , 'number_of_update' , 'number_of_delete' , 'number_of_patient_record' , 'number_of_unique_patient_record' , 'number_of_modules' , 'number_of_report_module' , 'number_of_finance_module' , 'number_of_patient_module' , 'number_of_lab_module' , 'number_of_pharmacy_module' , 'number_of_access_warning' , 'number_of_outside_access' , 'number_of_browser' , 'number_of_chrome' , 'number_of_ie' , 'number_of_safari' , 'number_of_firefox' , 'number_of_otherbrowser' , 'anomaly']]
t = df_testing['employee_role'].values.tolist()


anomaly_list = df_testing['anomaly'].values.tolist()

param_grid = [
  {'C': [1, 10, 100, 1000]}
 ]

bern_nb = Pipeline([('scale', StandardScaler()), ("bernoulli nb", BernoulliNB())])
mult_nb = Pipeline([('scale', StandardScaler()), ("multinomial nb", MultinomialNB())])
svm = Pipeline([('scale', StandardScaler()), ("linear svc", SVC(kernel='linear', probability=True))])
nn = Pipeline([('scale', StandardScaler()), ("neural network", MLPClassifier())])
knn = Pipeline([('scale', StandardScaler()), ("multinomial nb",  KNeighborsClassifier(5))])
lr = Pipeline([('scale', StandardScaler()), ("multinomial nb",  LogisticRegression())])
rf = Pipeline([('scale', StandardScaler()), ("multinomial nb", RandomForestClassifier())])
dt = Pipeline([('scale', StandardScaler()), ("multinomial nb", DecisionTreeClassifier())])

all_models = [
    ("bern_nb", bern_nb),
    ("nn", nn),
    ("knn", knn),
    ("lr", lr),
    ("rf", rf),
    ("dt", dt),
    ("svm", svm)
]

for name, model in all_models: 
  clf=model
  #print(name)
  clf.fit(X, y)
  result = clf.predict(S)
  #print(result)
  idx=0
  tp=0
  tn=0
  fp=0
  fn=0
  for res in result:
    if(res==t[idx]):
      if(anomaly_list[idx]==0):
        tn=tn+1
      else:
        fn=fn+1
    else:
      if(anomaly_list[idx]==1):
        tp=tp+1
      else:
        fp=fp+1
    idx=idx+1
  acc = float ((tp+tn)/(tp+tn+fp+fn))
  prec = float (tp/(tp+fp))
  rec =  float (tp/(tp+fn))
  f1=2*prec*rec/(prec+rec)
  print(name+' & '+ str(acc) + ' & ' +str(prec)+ ' & ' +str(rec)+ ' & ' +str(f1)+ '\\\\')

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
import pandas as pd
import csv
from google.colab import drive


from sklearn.naive_bayes import BernoulliNB, MultinomialNB
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import precision_recall_fscore_support, precision_score, recall_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score, cross_validate, cross_val_predict

from google.colab import drive
drive.mount('/content/gdrive')
path_folder ="/content/gdrive/My Drive/PhD/Prosper/"

df = pd.read_excel(path_folder+'features_data_with_label_v2.xlsx')
print(df['date'])
df['month']=df['date'].apply(lambda x: int(x.split('/')[1]))
print(df['month'])

df_first = df.loc[df['month'] <= 8]
print('training all: '+str(df_first.shape[0]))
df_training = df_first.loc[df_first['anomaly'] == 0]
print(df_training.shape[0])

df_testing = df.loc[df['month'] > 8]
print(df_testing.shape[0])

df_testing_anomaly = df.loc[df['anomaly'] == 1]
print(df_testing_anomaly.shape[0])

X = df_training[['number_of_create' , 'number_of_read' , 'number_of_update' , 'number_of_delete' , 'number_of_patient_record' , 'number_of_unique_patient_record' , 'number_of_modules' , 'number_of_report_module' , 'number_of_finance_module' , 'number_of_patient_module' , 'number_of_lab_module' , 'number_of_pharmacy_module' , 'number_of_access_warning' , 'number_of_outside_access' , 'number_of_browser' , 'number_of_chrome' , 'number_of_ie' , 'number_of_safari' , 'number_of_firefox' , 'number_of_otherbrowser' , 'anomaly']]
y = df_training['employee_role']

S = df_testing[['number_of_create' , 'number_of_read' , 'number_of_update' , 'number_of_delete' , 'number_of_patient_record' , 'number_of_unique_patient_record' , 'number_of_modules' , 'number_of_report_module' , 'number_of_finance_module' , 'number_of_patient_module' , 'number_of_lab_module' , 'number_of_pharmacy_module' , 'number_of_access_warning' , 'number_of_outside_access' , 'number_of_browser' , 'number_of_chrome' , 'number_of_ie' , 'number_of_safari' , 'number_of_firefox' , 'number_of_otherbrowser' , 'anomaly']]
t = df_testing['employee_role'].values.tolist()


anomaly_list = df_testing['anomaly'].values.tolist()

param_grid = [
  {'C': [1, 10, 100, 1000]}
 ]

bern_nb = Pipeline([('scale', MinMaxScaler()), ("bernoulli nb", BernoulliNB())])
mult_nb = Pipeline([('scale', MinMaxScaler()), ("multinomial nb", MultinomialNB())])
svm = Pipeline([('scale', MinMaxScaler()), ("linear svc", SVC(kernel='linear', probability=True))])
nn = Pipeline([('scale', MinMaxScaler()), ("neural network", MLPClassifier())])
knn = Pipeline([('scale', MinMaxScaler()), ("multinomial nb",  KNeighborsClassifier(5))])
lr = Pipeline([('scale', MinMaxScaler()), ("multinomial nb",  LogisticRegression())])
rf = Pipeline([('scale', MinMaxScaler()), ("multinomial nb", RandomForestClassifier())])
dt = Pipeline([('scale', MinMaxScaler()), ("multinomial nb", DecisionTreeClassifier())])

all_models = [
    ("mult_nb", mult_nb),
    ("bern_nb", bern_nb),
    ("nn", nn),
    ("knn", knn),
    ("lr", lr),
    ("rf", rf),
    ("dt", dt),
    ("svm", svm)
]


for name, model in all_models: 
  clf=model
  #print(name)
  clf.fit(X, y)
  result = clf.predict(S)
  #print(result)
  idx=0
  tp=0
  tn=0
  fp=0
  fn=0
  for res in result:
    if(res==t[idx]):
      if(anomaly_list[idx]==0):
        tn=tn+1
      else:
        fn=fn+1
    else:
      if(anomaly_list[idx]==1):
        tp=tp+1
      else:
        fp=fp+1
    idx=idx+1
  acc = float ((tp+tn)/(tp+tn+fp+fn))
  prec = float (tp/(tp+fp))
  rec =  float (tp/(tp+fn))
  f1=2*prec*rec/(prec+rec)
  print(name+' & '+ str(acc) + ' & ' +str(prec)+ ' & ' +str(rec)+ ' & ' +str(f1)+ '\\\\')

# Commented out IPython magic to ensure Python compatibility.
from sklearn.preprocessing import StandardScaler
from sklearn import preprocessing
from sklearn.preprocessing import MinMaxScaler
# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
import pandas as pd
import csv
from google.colab import drive


from sklearn.naive_bayes import BernoulliNB, MultinomialNB
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import precision_recall_fscore_support, precision_score, recall_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score, cross_validate, cross_val_predict

from google.colab import drive
drive.mount('/content/gdrive')
path_folder ="/content/gdrive/My Drive/PhD/Prosper/"

df = pd.read_excel(path_folder+'features_data_with_label_v2.xlsx')
print(df['date'])
df['month']=df['date'].apply(lambda x: int(x.split('/')[1]))
print(df['month'])

df_first = df.loc[df['month'] <= 8]
print(df_first)
df_training = df_first.loc[df_first['anomaly'] == 0]
print(df_training)

df_testing = df.loc[df['month'] > 8]
print(df_testing)

X = df_training[['number_of_create' , 'number_of_read' , 'number_of_update' , 'number_of_delete' , 'number_of_patient_record' , 'number_of_unique_patient_record' , 'number_of_modules' , 'number_of_report_module' , 'number_of_finance_module' , 'number_of_patient_module' , 'number_of_lab_module' , 'number_of_pharmacy_module' , 'number_of_access_warning' , 'number_of_outside_access' , 'number_of_browser' , 'number_of_chrome' , 'number_of_ie' , 'number_of_safari' , 'number_of_firefox' , 'number_of_otherbrowser' , 'anomaly']]
y = df_training['employee_role']

S = df_testing[['number_of_create' , 'number_of_read' , 'number_of_update' , 'number_of_delete' , 'number_of_patient_record' , 'number_of_unique_patient_record' , 'number_of_modules' , 'number_of_report_module' , 'number_of_finance_module' , 'number_of_patient_module' , 'number_of_lab_module' , 'number_of_pharmacy_module' , 'number_of_access_warning' , 'number_of_outside_access' , 'number_of_browser' , 'number_of_chrome' , 'number_of_ie' , 'number_of_safari' , 'number_of_firefox' , 'number_of_otherbrowser' , 'anomaly']]
t = df_testing['employee_role'].values.tolist()


anomaly_list = df_testing['anomaly'].values.tolist()

param_grid = [
  {'C': [1, 10, 100, 1000]}
 ]

bern_nb = Pipeline([('scale', StandardScaler()), ("bernoulli nb", BernoulliNB())])
mult_nb = Pipeline([('scale', StandardScaler()), ("multinomial nb", MultinomialNB())])
svm = Pipeline([('scale', StandardScaler()), ("linear svc", SVC(kernel='linear', probability=True))])
nn = Pipeline([('scale', StandardScaler()), ("neural network", MLPClassifier())])
knn = Pipeline([('scale', StandardScaler()), ("multinomial nb",  KNeighborsClassifier(5))])
lr = Pipeline([('scale', StandardScaler()), ("multinomial nb",  LogisticRegression())])
rf = Pipeline([('scale', StandardScaler()), ("multinomial nb", RandomForestClassifier())])
dt = Pipeline([('scale', StandardScaler()), ("multinomial nb", DecisionTreeClassifier())])

all_models = [
    ("bern_nb", bern_nb),
    ("nn", nn),
    ("knn", knn),
    ("lr", lr),
    ("rf", rf),
    ("dt", dt),
    ("svm", svm)
]

th_list = np.arange(0.05, 1.0, 0.05)
print(th_list)
allacc_list=[]
allprec_list=[]
allrec_list=[]
allf1_list=[]
allth_list=[]

for name, model in all_models: 
  clf=model
  #print(name)
  clf.fit(X, y)
  result = clf.predict_proba(S)
  #print(result)
  
  list_class = clf.classes_.tolist()
  acc_list=[]
  prec_list=[]
  rec_list=[]
  f1_list=[]
  for threshold in th_list:
    idx=0
    tp=0
    tn=0
    fp=0
    fn=0
    for res in result:
      if(res[list_class.index(t[idx])]>threshold):
        if(anomaly_list[idx]==0):
          tn=tn+1
        else:
          fn=fn+1
      else:
        if(anomaly_list[idx]==1):
          tp=tp+1
        else:
          fp=fp+1
      idx=idx+1
    acc = float ((tp+tn)/(tp+tn+fp+fn))
    prec = float (tp/(tp+fp))
    rec =  float (tp/(tp+fn))
    f1=2*prec*rec/(prec+rec)
    #print(name+' & '+ str(acc) + ' & ' +str(prec)+ ' & ' +str(rec)+ ' & ' +str(f1)+ '\\\\')
    #th_list.append(threshold)
    acc_list.append(acc)
    prec_list.append(prec)
    rec_list.append(rec)
    f1_list.append(f1)
  allacc_list.append(acc_list)
  allprec_list.append(prec_list)
  allrec_list.append(rec_list)
  allf1_list.append(f1_list)

idx=0
for name, model in all_models:
  print(name + '&'+ str(allf1_list[idx][1]))
  idx+=1

idx=0
for name, model in all_models:
  print(allrec_list[idx])
  idx+=1

idx=0
for name, model in all_models:
  print(allprec_list[idx])
  idx+=1

from matplotlib import pyplot as plt
#print(th_list)
idx=0
plt.plot(th_list, [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], label='mult_nb')
for name, model in all_models:
  plt.plot(th_list, allf1_list[idx], label=name)
  idx+=1
plt.legend()
plt.xlabel("Threshold")
plt.ylabel("F1 score")
plt.show()

from matplotlib import pyplot as plt
#print(th_list)
idx=0
plt.plot(th_list, [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], label='mult_nb')
for name, model in all_models:
  plt.plot(th_list, allprec_list[idx], label=name)
  idx+=1
plt.legend()
plt.xlabel("Threshold")
plt.ylabel("Precision")
plt.show()

from matplotlib import pyplot as plt
#print(th_list)
idx=0
plt.plot(th_list, [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], label='mult_nb')
for name, model in all_models:
  plt.plot(th_list, allrec_list[idx], label=name)
  idx+=1
plt.legend()
plt.xlabel("Threshold")
plt.ylabel("Recall")
plt.show()

from matplotlib import pyplot as plt
#print(th_list)
idx=0
plt.plot(th_list, [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], label='mult_nb')
for name, model in all_models:
  plt.plot(th_list, allacc_list[idx], label=name)
  idx+=1
plt.legend()
plt.xlabel("Threshold")
plt.ylabel("Accuracy")
plt.show()

from matplotlib import pyplot as plt
#print(th_list)
idx=0
plt.plot(th_list, [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], label='mult_nb')
for name, model in all_models:
  plt.plot(th_list, allacc_list[idx], label=name)
  idx+=1
plt.legend()
plt.xlabel("Threshold")
plt.ylabel("Accuracy")
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
import pandas as pd
import csv
from google.colab import drive


from sklearn.naive_bayes import BernoulliNB, MultinomialNB
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import precision_recall_fscore_support, precision_score, recall_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score, cross_validate, cross_val_predict

from google.colab import drive
drive.mount('/content/gdrive')
path_folder ="/content/gdrive/My Drive/PhD/Prosper/"

df = pd.read_excel(path_folder+'features_data_with_label_v2.xlsx')
print(df['date'])
df['month']=df['date'].apply(lambda x: int(x.split('/')[1]))
print(df['month'])

df_first = df.loc[df['month'] <= 8]
print(df_first)
df_training = df_first.loc[df_first['anomaly'] == 0]
print(df_training)

df_testing = df.loc[df['month'] > 8]
print(df_testing)

X = df_training[['number_of_create' , 'number_of_read' , 'number_of_update' , 'number_of_delete' , 'number_of_patient_record' , 'number_of_unique_patient_record' , 'number_of_modules' , 'number_of_report_module' , 'number_of_finance_module' , 'number_of_patient_module' , 'number_of_lab_module' , 'number_of_pharmacy_module' , 'number_of_access_warning' , 'number_of_outside_access' , 'number_of_browser' , 'number_of_chrome' , 'number_of_ie' , 'number_of_safari' , 'number_of_firefox' , 'number_of_otherbrowser' , 'anomaly']]
y = df_training['employee_role']

S = df_testing[['number_of_create' , 'number_of_read' , 'number_of_update' , 'number_of_delete' , 'number_of_patient_record' , 'number_of_unique_patient_record' , 'number_of_modules' , 'number_of_report_module' , 'number_of_finance_module' , 'number_of_patient_module' , 'number_of_lab_module' , 'number_of_pharmacy_module' , 'number_of_access_warning' , 'number_of_outside_access' , 'number_of_browser' , 'number_of_chrome' , 'number_of_ie' , 'number_of_safari' , 'number_of_firefox' , 'number_of_otherbrowser' , 'anomaly']]
t = df_testing['employee_role'].values.tolist()


anomaly_list = df_testing['anomaly'].values.tolist()

param_grid = [
  {'C': [1, 10, 100, 1000]}
 ]

bern_nb = Pipeline([('scale', MinMaxScaler()), ("bernoulli nb", BernoulliNB())])
mult_nb = Pipeline([('scale', MinMaxScaler()), ("multinomial nb", MultinomialNB())])
svm = Pipeline([('scale', MinMaxScaler()), ("linear svc", SVC(kernel='linear', probability=True))])
nn = Pipeline([('scale', MinMaxScaler()), ("neural network", MLPClassifier())])
knn = Pipeline([('scale', MinMaxScaler()), ("multinomial nb",  KNeighborsClassifier(5))])
lr = Pipeline([('scale', MinMaxScaler()), ("multinomial nb",  LogisticRegression())])
rf = Pipeline([('scale', MinMaxScaler()), ("multinomial nb", RandomForestClassifier())])
dt = Pipeline([('scale', MinMaxScaler()), ("multinomial nb", DecisionTreeClassifier())])

all_models = [
    ("mult_nb", mult_nb),
    ("bern_nb", bern_nb),
    ("nn", nn),
    ("knn", knn),
    ("lr", lr),
    ("rf", rf),
    ("dt", dt),
    ("svm", svm)
]

th_list = np.arange(0.05, 1.0, 0.05)
print(th_list)
allacc_list=[]
allprec_list=[]
allrec_list=[]
allf1_list=[]
allth_list=[]

for name, model in all_models: 
  clf=model
  #print(name)
  clf.fit(X, y)
  result = clf.predict_proba(S)
  #print(result)
  
  list_class = clf.classes_.tolist()
  acc_list=[]
  prec_list=[]
  rec_list=[]
  f1_list=[]
  for threshold in th_list:
    idx=0
    tp=0
    tn=0
    fp=0
    fn=0
    for res in result:
      if(res[list_class.index(t[idx])]>threshold):
        if(anomaly_list[idx]==0):
          tn=tn+1
        else:
          fn=fn+1
      else:
        if(anomaly_list[idx]==1):
          tp=tp+1
        else:
          fp=fp+1
      idx=idx+1
    acc = float ((tp+tn)/(tp+tn+fp+fn))
    prec = float (tp/(tp+fp))
    rec =  float (tp/(tp+fn))
    f1=2*prec*rec/(prec+rec)
    #print(name+' & '+ str(acc) + ' & ' +str(prec)+ ' & ' +str(rec)+ ' & ' +str(f1)+ '\\\\')
    #th_list.append(threshold)
    acc_list.append(acc)
    prec_list.append(prec)
    rec_list.append(rec)
    f1_list.append(f1)
  allacc_list.append(acc_list)
  allprec_list.append(prec_list)
  allrec_list.append(rec_list)
  allf1_list.append(f1_list)

idx=0
for name, model in all_models:
  print(int(allf1_list[idx][1]*1000))
  idx+=1

from matplotlib import pyplot as plt
#print(th_list)
idx=0
for name, model in all_models:
  plt.plot(th_list, allf1_list[idx], label=name)
  idx+=1
plt.legend()
plt.xlabel("Threshold")
plt.ylabel("F1 score")
plt.show()

from matplotlib import pyplot as plt
#print(th_list)
idx=0
for name, model in all_models:
  plt.plot(th_list, allprec_list[idx], label=name)
  idx+=1
plt.legend()
plt.xlabel("Threshold")
plt.ylabel("Precision")
plt.show()

from matplotlib import pyplot as plt
#print(th_list)
idx=0
for name, model in all_models:
  plt.plot(th_list, allprec_list[idx], label=name)
  idx+=1
plt.legend()
plt.xlabel("Threshold")
plt.ylabel("Precision")
plt.show()

from matplotlib import pyplot as plt
#print(th_list)
idx=0
for name, model in all_models:
  plt.plot(th_list, allrec_list[idx], label=name)
  idx+=1
plt.legend()
plt.xlabel("Threshold")
plt.ylabel("Recall")
plt.show()

from matplotlib import pyplot as plt
#print(th_list)
idx=0
for name, model in all_models:
  plt.plot(th_list, allacc_list[idx], label=name)
  idx+=1
plt.legend()
plt.xlabel("Threshold")
plt.ylabel("Accuracy")
plt.show()