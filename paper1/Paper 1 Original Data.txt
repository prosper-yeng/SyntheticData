# -*- coding: utf-8 -*-
"""Prosper_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NkGJ9jDLuC4XPbMcNkw6WO1X2vRdEEJT
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
import pandas as pd
import csv
from google.colab import drive


from sklearn.naive_bayes import BernoulliNB, MultinomialNB
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import precision_recall_fscore_support, precision_score, recall_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score, cross_validate, cross_val_predict

from google.colab import drive
drive.mount('/content/gdrive')
path_folder ="/content/gdrive/My Drive/PhD/Prosper/"

df = pd.read_excel(path_folder+'features_data_with_label_v2.xlsx')
print(df)
df = df.loc[df['anomaly'] == 0]
print(df)

X = df[['number_of_create' , 'number_of_read' , 'number_of_update' , 'number_of_delete' , 'number_of_patient_record' , 'number_of_unique_patient_record' , 'number_of_modules' , 'number_of_report_module' , 'number_of_finance_module' , 'number_of_patient_module' , 'number_of_lab_module' , 'number_of_pharmacy_module' , 'number_of_access_warning' , 'number_of_outside_access' , 'number_of_browser' , 'number_of_chrome' , 'number_of_ie' , 'number_of_safari' , 'number_of_firefox' , 'number_of_otherbrowser' , 'anomaly']]
y = df['employee_role']
param_grid = [
  {'C': [1, 10, 100, 1000]}
 ]

all_models = [
    ("mult_nb", MultinomialNB()),
    ("bern_nb", BernoulliNB()),
    ("nn", MLPClassifier()),
    ("knn", KNeighborsClassifier(5)),
    ("lr", LogisticRegression()),
    ("rf", RandomForestClassifier()),
    ("dt", DecisionTreeClassifier()),
    ("svm", SVC(kernel='linear', probability=True))
]

for name, model in all_models: 
  clf=model
  
  #result = cross_val_predict(clf, X, y, cv=5) # 5-fold Cross Validation
  #conf_mat = confusion_matrix(y, result)
  #print(conf_mat)
  #print("Precision Score : ",precision_score(y, result, average='micro'))
  #print("Recall Score : ",recall_score(y, result, average='micro'))
  scoring = ['precision_macro', 'recall_macro', 'f1_macro']
  scores = cross_validate(clf, X, y, cv=5)
  #print(scores)
  print(name + '&' + str(sum(scores['test_score'])/len(scores['test_score']))+'\\\\')
  #cross_val_score(clf, X, y, cv=5, scoring='precision_macro')

  #print(cross_val_score(clf, X, y, cv=5, scoring='recall_macro'))
  #print(cross_val_score(clf, X, y, cv=5, scoring='precision_micro'))
  #print(cross_val_score(clf, X, y, cv=5, scoring='recall_micro'))
  #print(cross_val_score(clf, X, y, cv=5, scoring='f1_macro'))
  #print(cross_val_score(clf, X, y, cv=5, scoring='f1_micro'))

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
import pandas as pd
import csv
from google.colab import drive


from sklearn.naive_bayes import BernoulliNB, MultinomialNB
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import precision_recall_fscore_support, precision_score, recall_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score, cross_validate, cross_val_predict

from google.colab import drive
drive.mount('/content/gdrive')
path_folder ="/content/gdrive/My Drive/PhD/Prosper/"

df = pd.read_excel(path_folder+'features_data_with_label_v2.xlsx')
print(df['date'])
df['month']=df['date'].apply(lambda x: int(x.split('/')[1]))
print(df['month'])

df_first = df.loc[df['month'] <= 8]
print('training all: '+str(df_first.shape[0]))
df_training = df_first.loc[df_first['anomaly'] == 0]
print(df_training.shape[0])

df_testing = df.loc[df['month'] > 8]
print(df_testing.shape[0])

df_testing_anomaly = df.loc[df['anomaly'] == 1]
print(df_testing_anomaly.shape[0])

X = df_training[['number_of_create' , 'number_of_read' , 'number_of_update' , 'number_of_delete' , 'number_of_patient_record' , 'number_of_unique_patient_record' , 'number_of_modules' , 'number_of_report_module' , 'number_of_finance_module' , 'number_of_patient_module' , 'number_of_lab_module' , 'number_of_pharmacy_module' , 'number_of_access_warning' , 'number_of_outside_access' , 'number_of_browser' , 'number_of_chrome' , 'number_of_ie' , 'number_of_safari' , 'number_of_firefox' , 'number_of_otherbrowser' , 'anomaly']]
y = df_training['employee_role']

S = df_testing[['number_of_create' , 'number_of_read' , 'number_of_update' , 'number_of_delete' , 'number_of_patient_record' , 'number_of_unique_patient_record' , 'number_of_modules' , 'number_of_report_module' , 'number_of_finance_module' , 'number_of_patient_module' , 'number_of_lab_module' , 'number_of_pharmacy_module' , 'number_of_access_warning' , 'number_of_outside_access' , 'number_of_browser' , 'number_of_chrome' , 'number_of_ie' , 'number_of_safari' , 'number_of_firefox' , 'number_of_otherbrowser' , 'anomaly']]
t = df_testing['employee_role'].values.tolist()


anomaly_list = df_testing['anomaly'].values.tolist()

param_grid = [
  {'C': [1, 10, 100, 1000]}
 ]

all_models = [
    ("mult_nb", MultinomialNB()),
    ("bern_nb", BernoulliNB()),
    ("knn", KNeighborsClassifier(5)),
    ("nn", MLPClassifier()),
    ("lr", LogisticRegression()),
    ("rf", RandomForestClassifier()),
    ("dt", DecisionTreeClassifier()),
    ("svm", SVC(kernel='linear', probability=True))
]

for name, model in all_models: 
  clf=model
  #print(name)
  clf.fit(X, y)
  result = clf.predict(S)
  #print(result)
  idx=0
  tp=0
  tn=0
  fp=0
  fn=0
  for res in result:
    if(res==t[idx]):
      if(anomaly_list[idx]==0):
        tn=tn+1
      else:
        fn=fn+1
    else:
      if(anomaly_list[idx]==1):
        tp=tp+1
      else:
        fp=fp+1
    idx=idx+1
  #print(tp, tn, fp, fn)
  acc = float ((tp+tn)/(tp+tn+fp+fn))
  prec = float (tp/(tp+fp))
  rec =  float (tp/(tp+fn))
  f1=2*prec*rec/(prec+rec)
  print(name+' & '+ str(acc) + ' & ' +str(prec)+ ' & ' +str(rec)+ ' & ' +str(f1)+ '\\\\')

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
import pandas as pd
import csv
from google.colab import drive


from sklearn.naive_bayes import BernoulliNB, MultinomialNB
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import precision_recall_fscore_support, precision_score, recall_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score, cross_validate, cross_val_predict

from google.colab import drive
drive.mount('/content/gdrive')
path_folder ="/content/gdrive/My Drive/PhD/Prosper/"

df = pd.read_excel(path_folder+'features_data_with_label_v2.xlsx')
print(df['date'])
df['month']=df['date'].apply(lambda x: int(x.split('/')[1]))
print(df['month'])

df_first = df.loc[df['month'] <= 8]
print(df_first)
df_training = df_first.loc[df_first['anomaly'] == 0]
print(df_training)

df_testing = df.loc[df['month'] > 8]
print(df_testing)

X = df_training[['number_of_create' , 'number_of_read' , 'number_of_update' , 'number_of_delete' , 'number_of_patient_record' , 'number_of_unique_patient_record' , 'number_of_modules' , 'number_of_report_module' , 'number_of_finance_module' , 'number_of_patient_module' , 'number_of_lab_module' , 'number_of_pharmacy_module' , 'number_of_access_warning' , 'number_of_outside_access' , 'number_of_browser' , 'number_of_chrome' , 'number_of_ie' , 'number_of_safari' , 'number_of_firefox' , 'number_of_otherbrowser' , 'anomaly']]
y = df_training['employee_role']

S = df_testing[['number_of_create' , 'number_of_read' , 'number_of_update' , 'number_of_delete' , 'number_of_patient_record' , 'number_of_unique_patient_record' , 'number_of_modules' , 'number_of_report_module' , 'number_of_finance_module' , 'number_of_patient_module' , 'number_of_lab_module' , 'number_of_pharmacy_module' , 'number_of_access_warning' , 'number_of_outside_access' , 'number_of_browser' , 'number_of_chrome' , 'number_of_ie' , 'number_of_safari' , 'number_of_firefox' , 'number_of_otherbrowser' , 'anomaly']]
t = df_testing['employee_role'].values.tolist()


anomaly_list = df_testing['anomaly'].values.tolist()

param_grid = [
  {'C': [1, 10, 100, 1000]}
 ]

all_models = [
    ("mult_nb", MultinomialNB()),
    ("bern_nb", BernoulliNB()),
    ("svm", SVC(kernel='linear', probability=True)),
    ("nn", MLPClassifier()),
    ("knn", KNeighborsClassifier(5)),
    ("lr", LogisticRegression()),
    ("rf", RandomForestClassifier()),
    ("dt", DecisionTreeClassifier())
]

th_list = np.arange(0.05, 1.0, 0.05)
print(th_list)
allacc_list=[]
allprec_list=[]
allrec_list=[]
allf1_list=[]
allth_list=[]

for name, model in all_models: 
  clf=model
  #print(name)
  clf.fit(X, y)
  result = clf.predict_proba(S)
  #print(result)
  
  list_class = clf.classes_.tolist()
  acc_list=[]
  prec_list=[]
  rec_list=[]
  f1_list=[]
  for threshold in th_list:
    idx=0
    tp=0
    tn=0
    fp=0
    fn=0
    for res in result:
      if(res[list_class.index(t[idx])]>threshold):
        if(anomaly_list[idx]==0):
          tn=tn+1
        else:
          fn=fn+1
      else:
        if(anomaly_list[idx]==1):
          tp=tp+1
        else:
          fp=fp+1
      idx=idx+1
    acc = float ((tp+tn)/(tp+tn+fp+fn))
    prec = float (tp/(tp+fp))
    rec =  float (tp/(tp+fn))
    f1=2*prec*rec/(prec+rec)
    #print(name+' & '+ str(acc) + ' & ' +str(prec)+ ' & ' +str(rec)+ ' & ' +str(f1)+ '\\\\')
    #th_list.append(threshold)
    acc_list.append(acc)
    prec_list.append(prec)
    rec_list.append(rec)
    f1_list.append(f1)
  allacc_list.append(acc_list)
  allprec_list.append(prec_list)
  allrec_list.append(rec_list)
  allf1_list.append(f1_list)

idx=0
for name, model in all_models:
  print(int(allf1_list[idx][1]*1000))
  idx+=1

print(allf1_list[2])

from matplotlib import pyplot as plt
#print(th_list)
idx=0
for name, model in all_models:
  plt.plot(th_list, allf1_list[idx], label=name)
  idx+=1
plt.legend()
plt.xlabel("Threshold")
plt.ylabel("F1 score")
plt.show()

from matplotlib import pyplot as plt
#print(th_list)
idx=0
for name, model in all_models:
  plt.plot(th_list, allprec_list[idx], label=name)
  idx+=1
plt.legend()
plt.xlabel("Threshold")
plt.ylabel("Precision")
plt.show()

from matplotlib import pyplot as plt
#print(th_list)
idx=0
for name, model in all_models:
  plt.plot(th_list, allrec_list[idx], label=name)
  idx+=1
plt.legend()
plt.xlabel("Threshold")
plt.ylabel("Recall")
plt.show()

from matplotlib import pyplot as plt
#print(th_list)
idx=0
for name, model in all_models:
  plt.plot(th_list, allacc_list[idx], label=name)
  idx+=1
plt.legend()
plt.xlabel("Threshold")
plt.ylabel("Accuracy")
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
import pandas as pd
import csv
from google.colab import drive


from sklearn.naive_bayes import BernoulliNB, MultinomialNB
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import precision_recall_fscore_support, precision_score, recall_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score, cross_validate, cross_val_predict

from google.colab import drive
drive.mount('/content/gdrive')
path_folder ="/content/gdrive/My Drive/PhD/Prosper/"

df = pd.read_excel(path_folder+'features_data_with_label_v2.xlsx')

df = df.sample(frac=1).reset_index(drop=True)

training_percentage=70

number_of_training = int (df.shape[0]*training_percentage/100)

df_training = df[:number_of_training]
print(df_training)
df_training = df_training.loc[df_training['anomaly'] == 0]

df_testing = df[number_of_training:]
print(df_testing)

X = df_training[['number_of_create' , 'number_of_read' , 'number_of_update' , 'number_of_delete' , 'number_of_patient_record' , 'number_of_unique_patient_record' , 'number_of_modules' , 'number_of_report_module' , 'number_of_finance_module' , 'number_of_patient_module' , 'number_of_lab_module' , 'number_of_pharmacy_module' , 'number_of_access_warning' , 'number_of_outside_access' , 'number_of_browser' , 'number_of_chrome' , 'number_of_ie' , 'number_of_safari' , 'number_of_firefox' , 'number_of_otherbrowser' , 'anomaly']]
y = df_training['employee_role']

S = df_testing[['number_of_create' , 'number_of_read' , 'number_of_update' , 'number_of_delete' , 'number_of_patient_record' , 'number_of_unique_patient_record' , 'number_of_modules' , 'number_of_report_module' , 'number_of_finance_module' , 'number_of_patient_module' , 'number_of_lab_module' , 'number_of_pharmacy_module' , 'number_of_access_warning' , 'number_of_outside_access' , 'number_of_browser' , 'number_of_chrome' , 'number_of_ie' , 'number_of_safari' , 'number_of_firefox' , 'number_of_otherbrowser' , 'anomaly']]
t = df_testing['employee_role'].values.tolist()


anomaly_list = df_testing['anomaly'].values.tolist()

param_grid = [
  {'C': [1, 10, 100, 1000]}
 ]

all_models = [
    ("mult_nb", MultinomialNB()),
    ("bern_nb", BernoulliNB()),
    ("linear svc", SVC(kernel='linear', probability=True)),
    ("nn", MLPClassifier()),
    ("knn_binary", KNeighborsClassifier(5)),
    ("lr", LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=1)),
    ("rf_binary", RandomForestClassifier()),
    ("dt_binary", DecisionTreeClassifier())
]

threshold=0.15

for name, model in all_models: 
  clf=model
  print(name)
  clf.fit(X, y)
  result = clf.predict_proba(S)
  #print(result)
  idx=0
  tp=0
  tn=0
  fp=0
  fn=0

  list_class = clf.classes_.tolist()

  for res in result:
    if(res[list_class.index(t[idx])]>threshold):
      if(anomaly_list[idx]==0):
        tn=tn+1
      else:
        fn=fn+1
    else:
      if(anomaly_list[idx]==1):
        tp=tp+1
      else:
        fp=fp+1
    idx=idx+1
  print(tp, tn, fp, fn)
  prec = float (tp/(tp+fp))
  rec =  float (tp/(tp+fn))
  f1=2*prec*rec/(prec+rec)
  print(prec, rec, f1)